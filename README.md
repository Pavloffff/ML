# Студент группы М8О-407Б-21 Павлов Иван Дмитриевич

В файлах ```lab1.ipynb``` - ```lab5.ipynb``` лежат выполненные лабораторные работы 1-5 по курсу "Методы, средства и технологии мультимедиа"

# Подведение итогов

# Метрика качества на тестовом наборе данных

## 1. K-Nearest Neighbors (KNN)

### Регрессия:

| Модель                      | MSE         | MAE     | RMSE   | R²    |
|-----------------------------|-------------|---------|--------|-------|
| Бейзлайн                    | 14,042,775,030.18 | 85,680.61 | 118,502.22 | 0.68 |
| Улучшенный бейзлайн         | 6,046,709,395.42 | 53,041.35 | 77,760.59 | 0.86 |
| Собственная имплементация | 5,473,783,027.35 | 73,985.02 | 4,741.85 | 0.87 |

### Классификация:

| Модель                      | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Бейзлайн                    | 59.84%              | 59.31%                      | 59.84%           | 59.28%   |
| Улучшенный бейзлайн         | 92.68%              | 92.76%                      | 92.68%           | 92.65%   |
| Собственная имплементация | 92.68%              | 92.76%                      | 92.68%           | 92.65%   |

## 2. Линейные модели

### Регрессия:

| Модель                      | MSE         | MAE     | RMSE   | R²    |
|-----------------------------|-------------|---------|--------|-------|
| Бейзлайн                    | 11,149,777,983.22                  | 78,678.04                         | 105,592.51                                | 0.74                             |
| Улучшенный бейзлайн         | 3,538,831,774.21                   | 42,671.33                        |  59488.08                                 | 0.92                             |
| Собственная имплементация | 4,230,659,265.36                   | 49,504.56                         | 65,043.52                                 | 0.90               |

### Классификация:

| Модель                      | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Бейзлайн                    | 90.40%              | 90.48%                      | 90.29%           | 90.39%   |
| Улучшенный бейзлайн         | 90.40%              | 90.48%                      | 90.29%           | 90.39%  |
| Собственная имплементация | 93.49%              | 93.49%                      | 93.85%           | 93.51%   |

## 3. Решающее дерево

### Регрессия:

| Модель                      | MSE         | MAE     | RMSE   | R²    |
|-----------------------------|-------------|---------|--------|-------|
| Бейзлайн                    | 20,273,328,916.06 | 102,424.98        | 142,384.44        | 0.53   |
| Улучшенный бейзлайн         | 205,602,352.76    | 7,791.84          | 14,338.84         | 1.00   |
| Собственная имплементация | 5,038,823,976.54  | 53,893.98         | 70,984.67         | 0.88   |

### Классификация:

| Модель                      | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Бейзлайн                    | 94.41%              | 93.26%                       | 94.05%           | 93.66%   |
| Улучшенный бейзлайн         | 94.46%              | 94.46%                       | 94.46%           | 94.46%   |
| Собственная имплементация | 90.17%              | 89.53%                       | 87.89%           | 88.70%   |

## 4. Случайный лес (Random Forest)

### Регрессия:

| Модель                      | MSE         | MAE     | RMSE   | R²    |
|-----------------------------|-------------|---------|--------|-------|
| Бейзлайн                    | 11,733,930,099.60              | 78,532.56                       | 108,323.27        | 0.73            |
| Улучшенный бейзлайн         | 100,779,317.02                 | 3,647.85                        | 10,038.89         | 1.00           |
| Собственная имплементация | 133,382,029.63                  | 5,673.35                        | 11,549.11         | 1.00                        |

### Классификация:

| Модель                      | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Бейзлайн                    | 96.23%              | 97.18%                       | 94.14%           | 95.64%   |
| Улучшенный бейзлайн         | 96.31%              | 96.33%                       | 96.31%           | 96.30%   |
| Собственная имплементация | 86.17%              | 94.02%                       | 73.14%           | 82.28%   |

## 5. Градиентный бустинг (Gradient Boosting)

### Регрессия:

| Модель                      | MSE         | MAE     | RMSE   | R²    |
|-----------------------------|-------------|---------|--------|-------|
| Бейзлайн                    | 10,089,643,014.07               | 75,065.73                       | 100,447.21        | 0.75                        |
| Улучшенный бейзлайн         | 8,976,718,649.15                  | 70,154.13                        | 94,745.54         | 0.79                        |
| Собственная имплементация | 8,976,718,649.15                  | 70,154.13                        | 94,745.54         | 0.79                        |

### Классификация:

| Модель                      | Accuracy | Precision | Recall | F1-score |
|-----------------------------|----------|-----------|--------|----------|
| Бейзлайн                    | 94.14%    | 94.50%    | 92.02%  | 93.24% |
| Улучшенный бейзлайн         | 93.52%    | 93.93%    | 91.03%  | 92.46% |
| Собственная имплементация   | 58.87%    | 51.63%    | 99.98%  | 68.10% |


# Итоговые выводы по метрикам

## 1. K-Nearest Neighbors (KNN)

### Регрессия:
- Улучшенный бейзлайн значительно улучшил результаты по сравнению с обычным бейзлайном: ошибка MSE снизилась на 57%, MAE — на 38%, а R² увеличился с 0.68 до 0.86.  
- Собственная имплементация также показала результат, сопоставимый с улучшенным бейзлайном.

### Классификация:
- Улучшенный бейзлайн существенно улучшил точность (Accuracy) и F1-score, увеличив их до 92.68%.  
- Собственная имплементация показала идентичный результат улучшенному бейзлайну.

## 2. Линейные модели

### Регрессия:
- Улучшенный бейзлайн показал значительное улучшение: R² увеличился до 0.92, а ошибки (MSE и MAE) сократились более чем на 65% по сравнению с обычным бейзлайном.  
- Собственная имплементация также улучшила результаты, но уступила улучшенному бейзлайну (R²: 0.90 против 0.92).

### Классификация:
- Улучшенный бейзлайн не показал прироста метрик по сравнению с обычным.  
- Собственная имплементация превзошла оба подхода, увеличив Accuracy до 93.49% и F1-score до 93.51%.

## 3. Решающее дерево

### Регрессия:
- Улучшенный бейзлайн показал практически идеальные результаты (R² = 1.00, минимальные ошибки).  
- Собственная имплементация улучшила результаты по сравнению с обычным бейзлайном, но уступила улучшенному бейзлайну.

### Классификация:
- Улучшенный бейзлайн показал наилучшие результаты (Accuracy: 94.46%, F1-score: 94.46%).  
- Собственная имплементация показала снижение метрик, особенно Recall (87.89%).

## 4. Случайный лес (Random Forest)

### Регрессия:
- Улучшенный бейзлайн продемонстрировал наилучшие результаты: R² = 1.00, минимальные ошибки (MSE: 100,779,317.02).  
- Собственная имплементация также достигла R² = 1.00, но показала немного более высокие ошибки.

### Классификация:
- Улучшенный бейзлайн немного улучшил результаты по сравнению с обычным (Accuracy: 96.31% против 96.23%).  
- Собственная имплементация показала значительное снижение точности (86.17%) и F1-score (82.28%).

## 5. Градиентный бустинг (Gradient Boosting)

### Регрессия:
- Все подходы (обычный, улучшенный бейзлайн и собственная имплементация) показали схожие результаты, с R² = 0.79 и минимальными различиями в ошибках.

### Классификация:
- Улучшенный бейзлайн немного уступил обычному (Accuracy: 93.52% против 94.14%).  
- Собственная имплементация значительно отстала: Accuracy: 58.87%, F1-score: 68.10%.

---

# Общий вывод
- Улучшенный бейзлайн в большинстве случаев улучшил метрики, особенно в задачах регрессии для линейных моделей, случайного леса и решающего дерева.
- Собственная имплементация часто уступает улучшенному бейзлайну, особенно в задачах классификации, но показывает достойные результаты в регрессионных задачах (особенно для KNN и решающего дерева).
- Наилучшие результаты в классификации показали улучшенный бейзлайн для случайного леса и решающего дерева, а также собственная имплементация для линейных моделей.
- В задачах регрессии идеальные результаты (R² = 1.00) продемонстрировали улучшенные бейзлайны для решающего дерева и случайного леса.